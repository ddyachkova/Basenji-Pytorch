{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266a8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, ConcatDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "from itertools import groupby\n",
    "import gzip \n",
    "from io import BytesIO\n",
    "from time import time \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pyBigWig\n",
    "from scipy.sparse import csc_matrix\n",
    "import math \n",
    "\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "import functools\n",
    "\n",
    "import captum \n",
    "from captum.attr import DeepLift, DeepLiftShap\n",
    "# import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32be34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115972ab",
   "metadata": {},
   "source": [
    "To run a classification, we need to update the last block in the model (conv_block_5). Pytorch's cross entropy loss accepts logits as input, so we need the model's very last layer to be linear. \n",
    "I tried to update the conv_block_5 attribute using class inheritannce and attribute overriding, but it did not work for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba5d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upd_GELU(nn.Module):\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return torch.sigmoid(torch.Tensor([1.702]).cuda() * input) * input\n",
    "\n",
    "def ones_(tensor: Tensor) -> Tensor:\n",
    "    return torch.ones_like(tensor)\n",
    "\n",
    "def zeros_(tensor: Tensor) -> Tensor:\n",
    "    return torch.zeros_like(tensor)\n",
    "\n",
    "class BasenjiModel_Classif(nn.Module):\n",
    "    def __init__(self, num_targets, n_channel=4, max_len=128, \n",
    "                 conv1kc=64, conv1ks=15, conv1st=1, conv1pd=7, pool1ks=8, pool1st=1 , pdrop1=0.4, #conv_block_1 parameters\n",
    "                 conv2kc=64, conv2ks=5, conv2st=1, conv2pd=3, pool2ks=4 , pool2st=1, pdrop2=0.4, #conv_block_2 parameters\n",
    "                 conv3kc=round(64*1.125), conv3ks=5, conv3st=1, conv3pd=3, pool3ks=4 , pool3st=1, pdrop3=0.4, #conv_block_2 parameters\n",
    "                 convdc = 6, convdkc=32 , convdks=3, debug=False):                 \n",
    "        super(BasenjiModel_Classif, self).__init__()\n",
    "        \n",
    "        self.convdc = convdc\n",
    "        self.debug = debug\n",
    "        self.num_targets =  num_targets\n",
    "        ## CNN + dilated CNN\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            upd_GELU(),\n",
    "            nn.Conv1d(n_channel, conv1kc, kernel_size=conv1ks, stride=conv1st, padding=conv1pd, bias=False),\n",
    "            nn.BatchNorm1d(conv1kc, momentum=0.9, affine=True),\n",
    "            nn.MaxPool1d(kernel_size=pool1ks),\n",
    "            nn.Dropout(p=0.2))\n",
    "                \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            upd_GELU(),\n",
    "            nn.Conv1d(conv1kc, conv2kc, kernel_size=conv2ks, stride=conv2st, padding=conv2pd, bias=False),\n",
    "            nn.BatchNorm1d(conv2kc, momentum=0.9, affine=True),\n",
    "            nn.MaxPool1d(kernel_size=pool2ks),\n",
    "            nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            upd_GELU(),\n",
    "            nn.Conv1d(conv2kc, round(conv2kc*1.125), kernel_size=conv3ks, stride=conv3st, padding=conv3pd, bias=False),\n",
    "            nn.BatchNorm1d(conv3kc, momentum=0.9, affine=True),\n",
    "            nn.MaxPool1d(kernel_size=pool3ks),\n",
    "            nn.Dropout(p=0.2))\n",
    "        \n",
    "\n",
    "        self.dilations = nn.ModuleList()\n",
    "        for i in range(convdc):\n",
    "            padding = 2**(i)\n",
    "            self.dilations.append(nn.Sequential(\n",
    "                upd_GELU(),\n",
    "                nn.Conv1d(conv3kc, 32, kernel_size=3, padding=padding, dilation=2**i, bias=False),\n",
    "                nn.BatchNorm1d(32, momentum=0.9, affine=True), \n",
    "                upd_GELU(),\n",
    "                nn.Conv1d(32, 72, kernel_size=1, padding=0, bias=False),\n",
    "                nn.BatchNorm1d(72, momentum=0.9, affine=True), \n",
    "                nn.Dropout(p=0.25)))\n",
    "            \n",
    "        self.conv_block_4 = nn.Sequential(\n",
    "            upd_GELU(),\n",
    "            nn.Conv1d(72, 64, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm1d(64, momentum=0.9, affine=True), \n",
    "            nn.Dropout(p=0.1)) \n",
    "            \n",
    "        self.conv_block_5 = nn.Sequential(\n",
    "            upd_GELU(),\n",
    "            nn.Linear(64, self.num_targets, bias=True)) \n",
    "\n",
    "    \n",
    "        self.conv_block_1[1].weight.data = self.truncated_normal(self.conv_block_1[1].weight, 0.0, np.sqrt(2/60)) #4\n",
    "        self.conv_block_2[1].weight.data = self.truncated_normal(self.conv_block_2[1].weight, 0.0, np.sqrt(2/322)) # conv1kc\n",
    "        self.conv_block_3[1].weight.data = self.truncated_normal(self.conv_block_3[1].weight, 0.0, np.sqrt(2/322)) # conv1kc\n",
    "        self.conv_block_4[1].weight.data = self.truncated_normal(self.conv_block_4[1].weight, 0.0, np.sqrt(2/72)) # 72\n",
    "        self.conv_block_5[1].weight.data = self.truncated_normal(self.conv_block_5[1].weight, 0.0, np.sqrt(2/64)) # 64        \n",
    "        self.conv_block_1[2].weight.data = ones_(self.conv_block_1[2].weight)\n",
    "        self.conv_block_2[2].weight.data = ones_(self.conv_block_2[2].weight)\n",
    "        self.conv_block_3[2].weight.data = ones_(self.conv_block_3[2].weight)\n",
    "        self.conv_block_4[2].weight.data = ones_(self.conv_block_4[2].weight)\n",
    "\n",
    "        \n",
    "        for i in range(convdc):\n",
    "            self.dilations[i][1].weight.data = self.truncated_normal(self.dilations[i][1].weight, 0.0, np.sqrt(2/218)) # 72\n",
    "            self.dilations[i][-2].weight.data = self.truncated_normal(self.dilations[i][-2].weight, 0.0, np.sqrt(2/32)) # 32\n",
    "            self.dilations[i][2].weight.data = zeros_(self.dilations[i][2].weight)\n",
    "            self.dilations[i][-2].weight.data = ones_(self.dilations[i][-2].weight)\n",
    "\n",
    "    \n",
    "    def truncated_normal(self, t, mean, std):\n",
    "        torch.nn.init.normal_(t, mean, std)\n",
    "        while True:\n",
    "            cond = torch.logical_or(t < (mean - 2.28*std), t > (mean + 2.28*std))\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(cond, torch.nn.init.normal_(torch.ones(t.shape), mean=mean, std=std), t)\n",
    "        return t\n",
    "\n",
    "\n",
    "    def forward(self, seq):\n",
    "        if self.debug: \n",
    "            print (seq.shape)\n",
    "        seq = self.conv_block_1(seq)\n",
    "        if self.debug: \n",
    "            print ('conv1', seq.shape)\n",
    "        seq = self.conv_block_2(seq)\n",
    "        if self.debug: \n",
    "            print ('conv2', seq.shape)\n",
    "        seq = self.conv_block_3(seq)\n",
    "        if self.debug: \n",
    "            print ('conv3', seq.shape)\n",
    "        for i in range(self.convdc):\n",
    "            if i == 0:\n",
    "                y = self.dilations[i](seq)\n",
    "            if i >= 1:\n",
    "                y = y.add(self.dilations[i](seq))\n",
    "            if self.debug: \n",
    "                print ('dil', i, self.dilations[i](seq).shape)\n",
    "        if self.debug:\n",
    "            print ('y', y.shape)\n",
    "        res = self.conv_block_4(y)\n",
    "        if self.debug: \n",
    "            print ('res', res.shape)\n",
    "        res_lin = res.transpose(1, 2)\n",
    "        if self.debug: \n",
    "            print ('res_lin', res_lin.shape)\n",
    "        res = self.conv_block_5(res_lin)\n",
    "        if self.debug: \n",
    "            print ('res', res.shape)\n",
    "        return res\n",
    "        \n",
    "    def compile(self, device='cpu'):\n",
    "        self.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a24cb1",
   "metadata": {},
   "source": [
    "First step for the analysis is to initialize and load the model, trainer and get the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e055b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vals = { \n",
    "\"optimizer\" : \"Adam\", \n",
    "\"init_lr\": 0.001, \n",
    "\"optimizer_momentum\": 0.9, \n",
    "\"weight_decay\": 1e-3, \n",
    "\"loss\": \"bce\", \n",
    "\"num_targets\": 1,\n",
    "\"seq_len\": 128*128*8,\n",
    "\"target_window\": 1024*32,\n",
    "\"batch_size\": 1,\n",
    "\"cut\": 0.8,\n",
    "\"num_workers\": 0,\n",
    "\"num_epochs\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d29aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memmap_data_contigs_dir = '/data/users/goodarzilab/darya/work/basenji_pytorch/hg38_memmaps'\n",
    "targets_memmap_data_dir_cl = '/data/users/goodarzilab/darya/work/basenji_pytorch/hg38_targets_memmaps_CL.ATAC'\n",
    "targets_memmap_data_dir_pdx = '/data/users/goodarzilab/darya/work/basenji_pytorch/hg38_targets_memmaps_PDX.ATAC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265c8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasenjiModel_Classif(num_targets=1)\n",
    "model.compile('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bd9f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dsets\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(param_vals, model, memmap_data_contigs_dir, targets_memmap_data_dir_cl, targets_memmap_data_dir_pdx, mode='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672e9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model(trainer.model, \"basenji_toy_upd_motif_32k_recfield_13epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945b02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = trainer.make_loaders(augm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc27f157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "X, y = trainer.get_input(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19af53",
   "metadata": {},
   "source": [
    "Then, for the baseline data, we shuffle out inputs. Since the trainer outputs one-hot incoded data, we reverse that step, randomly permute the values and one-hot encode them again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "147da04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ints = torch.argmax(X, dim=1).squeeze()#.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d24f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randperm(X_ints.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e09706b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_shuffled = torch.stack([X_ints[i][idx] for i in range(X_ints.shape[0])])\n",
    "# X_shuffled = torch.transpose(F.one_hot(X_shuffled), 2, 1)#.unsqueeze(0)\n",
    "\n",
    "X_shuffled = X_ints[idx]\n",
    "X_shuffled = torch.transpose(F.one_hot(X_shuffled), 1, 0).unsqueeze(0)\n",
    "# X_shuffled = F.one_hot(X_shuffled).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e5c8b3",
   "metadata": {},
   "source": [
    "Next, we use the DeepLift algorithm from the Captum package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc494bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/users/goodarzilab/darya/anaconda3/envs/basenji_pytorch/lib/python3.9/site-packages/captum/_utils/gradient.py:56: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/data/users/goodarzilab/darya/anaconda3/envs/basenji_pytorch/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:320: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n",
      "/data/users/goodarzilab/darya/anaconda3/envs/basenji_pytorch/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:452: UserWarning: An invalid module MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  warnings.warn(\n",
      "/data/users/goodarzilab/darya/anaconda3/envs/basenji_pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/data/users/goodarzilab/darya/anaconda3/envs/basenji_pytorch/lib/python3.9/site-packages/captum/attr/_core/deep_lift.py:452: UserWarning: An invalid module MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False) is detected. Saved gradients will\n",
      "                be used as the gradients of the module's input tensor.\n",
      "                See MaxPool1d as an example.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dl = DeepLift(trainer.model)\n",
    "attribution = dl.attribute(X, baselines=X_shuffled.float(), target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526f4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucs = np.arange(4)\n",
    "inp_vals = X.cpu().detach().numpy()\n",
    "attr = attribution.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11187339",
   "metadata": {},
   "source": [
    "Then, for each minibatch, we collect the attribute values. They are grouped for each nucleotide, so it's the same thing as reversing one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ceb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucs_vals = np.zeros((inp_vals.shape[0], inp_vals.shape[-1]))\n",
    "attr_vals = np.zeros((inp_vals.shape[0], inp_vals.shape[-1]))\n",
    "\n",
    "\n",
    "for j in range(inp_vals.shape[0]):\n",
    "    for i in range(len(nucs)):\n",
    "        ids = np.where(inp_vals[j][i] == 1.)\n",
    "        nucs_vals[j][ids] = nucs[i]\n",
    "        for idx in ids: \n",
    "            attr_vals[j][idx] = attr[j][i][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763a81b",
   "metadata": {},
   "source": [
    "Finally, we need to cross-reference the deeplift values with the actual locations of the motifs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26b03f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "motif_str = '202131'\n",
    "\n",
    "def return_ids(test_str, motif_str):\n",
    "    ind_found = np.hstack([[m.start() + i] for m in re.finditer(motif_str, test_str) for i in range(len(motif_str))])\n",
    "    return ind_found\n",
    "\n",
    "def get_motif_loc(seq):\n",
    "    seq_subset_str = \"\".join([str(int(s)) for s in seq])\n",
    "    test_empty = np.zeros(len(seq_subset_str))\n",
    "    ids = return_ids(seq_subset_str, motif_str)\n",
    "    test_empty[ids] = 1\n",
    "    return ids, test_empty\n",
    "\n",
    "def get_true_targets(labels_again):\n",
    "    ids, test_empty = get_motif_loc(labels_again)\n",
    "    rand_ids = ids[0::6]\n",
    "    diff_ids = np.diff(rand_ids)\n",
    "    bins = np.arange(0, labels_again.shape[0], 128)\n",
    "    # bin_indices = np.digitize(rand_ids[np.where(diff_ids >= 180)[0]], bins) #rand_ids[diff_ids_range], bins)\n",
    "    bin_indices = np.digitize(rand_ids[np.where(diff_ids >= 180)], bins) #rand_ids[diff_ids_range], bins)\n",
    "    targets = torch.zeros(len(bins))\n",
    "    targets[bin_indices] = 1\n",
    "    return targets, rand_ids[np.where(diff_ids >= 160)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd647449",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_true_targets(X_ints)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f70cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_empty = torch.zeros(X_ints.shape)\n",
    "targets_empty[targets] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f8f9bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(attr_vals[0])-10000), np.abs(attr_vals[0][10000:]), alpha=0.5)\n",
    "plt.plot(np.arange(len(attr_vals[0])-10000), targets_empty[10000:]/(10**2), alpha=0.5, color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenji_pytorch",
   "language": "python",
   "name": "basenji_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
