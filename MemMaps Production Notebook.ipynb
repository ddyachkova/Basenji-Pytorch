{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de26e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from itertools import groupby\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af4bdc3",
   "metadata": {},
   "source": [
    "First, we need to define the location of the fasta file, the gap file, the directory with the targets, and the directories, where to save the input and target memory maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9c4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = '/data/users/goodarzilab/darya/work/Datasets'\n",
    "target_dir = '/data/users/goodarzilab/darya/work/Datasets/corderoLabData/bwOS.PDX.ATAC'\n",
    "memmap_data_dir = os.path.join(os.getcwd(), 'memmaps_test')\n",
    "targets_memmap_data_dir = os.path.join(os.getcwd(), 'targets_memmaps_test')\n",
    "\n",
    "\n",
    "fasta_file = os.path.join(datasets_dir, 'hg38.fa')\n",
    "gaps_file = os.path.join(datasets_dir, 'hg38_gaps.bed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047bf61",
   "metadata": {},
   "source": [
    "Then, we define the list with full directories of each of the targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b33fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list = os.listdir(target_dir)\n",
    "targets_path_list = [os.path.join(target_dir, tar) for tar in targets_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e932d",
   "metadata": {},
   "source": [
    "Then, we need to create a dictionary with nucleotides - both lower and upper case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e17e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'T', 'C', 'G', 'N', 'a', 't', 'c', 'g', 'n'], dtype='<U1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nucs = np.array([\"A\", \"T\", \"C\", \"G\", \"N\"])\n",
    "mapping = {u:i for i,u in enumerate(nucs)}\n",
    "nucs_lower = [nuc.lower() for nuc in nucs]\n",
    "mapping_lower = {u:i for i,u in enumerate(nucs_lower)}\n",
    "\n",
    "mapping.update(mapping_lower)\n",
    "nucs = np.append(nucs, nucs_lower)\n",
    "nucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184cbd5",
   "metadata": {},
   "source": [
    "Next, we open the gaps file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3448d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(gaps_file) as f:\n",
    "    for line in f:\n",
    "        lines.append(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea0dbc",
   "metadata": {},
   "source": [
    "For the sake of having a full list of chromosome names, we pul it from a random bw file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c57db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pyBigWig.open(os.path.join(target_dir, 'PDX008_1.bw'), 'r')\n",
    "chrom_seq = target.chroms() \n",
    "chrom_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798e90b",
   "metadata": {},
   "source": [
    "With the gap information derived above, we create a dictionary where each cromosome name corresponds to the \"non-gap\" locations, i.e., with the gaps extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf85522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_gaps = dict()\n",
    "for i, g in itertools.groupby(lines, lambda x: x[0]):\n",
    "    if i in list(chrom_seq.keys()):\n",
    "        arr =  [np.array(el[1:3]).astype(int) for el in g]\n",
    "        arr = sorted(arr, key=itemgetter(0))\n",
    "        arr_corrected = [[int(arr[i][1]), int(arr[i+1][0])] for i in range(len(arr)-1) if int(arr[i][1]) != int(arr[i+1][0])]\n",
    "        if int(arr[-1][1]) != chrom_seq[i]:\n",
    "            arr_corrected.append([int(arr[-1][1]), chrom_seq[i]])        \n",
    "        chrom_gaps[i] = arr_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed3c31",
   "metadata": {},
   "source": [
    "The iterator below opens a fast file, and for each header (chromosome), extracts the fill sequence as a long string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04828fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_iter(fasta_name):\n",
    "    \"\"\"\n",
    "    modified from Brent Pedersen\n",
    "    Correct Way To Parse A Fasta File In Python\n",
    "    given a fasta file. yield tuples of header, sequence\n",
    "    \"\"\"\n",
    "    fh = open(fasta_name)\n",
    "    faiter = (x[1] for x in groupby(fh, lambda line: line[0] == \">\"))\n",
    "\n",
    "    for header in faiter:\n",
    "        headerStr = header.__next__()[1:].strip()\n",
    "        seq = \"\".join(s.strip() for s in faiter.__next__())\n",
    "\n",
    "        yield (headerStr, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70916e2e",
   "metadata": {},
   "source": [
    "The loop below uses the iterator defined above, opens the fasta file, extracts the gaps, and saves the result as a memory map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b48de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fiter = fasta_iter(fasta_file)\n",
    "for ff in fiter:\n",
    "    headerStr, seq = ff\n",
    "    seq = np.array(list(seq))\n",
    "    print (headerStr)\n",
    "    for key in chrom_gaps.keys():\n",
    "        if key == headerStr:\n",
    "            memmap_name = key + \"_sequence.dta\"\n",
    "            els_corrected = chrom_gaps[key]\n",
    "            lengths = [e[1] - e[0] for e in els_corrected]\n",
    "            contigs_shape = sum(lengths)\n",
    "            lengths.insert(0, 0)\n",
    "            lengths_idx = np.cumsum(lengths)\n",
    "            chr_contigs =  np.memmap(os.path.join(memmap_data_dir, (key + \"_contigs_sequence.dta\")), mode='w+', dtype='float32', shape=(contigs_shape))\n",
    "            for i in range(len(els_corrected)):\n",
    "                seq_subset = seq[els_corrected[i][0]:els_corrected[i][1]]\n",
    "                seq_subset_mapped = np.zeros((len(seq_subset),))\n",
    "                for nuc in nucs:\n",
    "                    j = np.where(seq_subset[0:len(seq_subset)] == nuc)[0]\n",
    "                    seq_subset_mapped[j] = mapping[nuc]\n",
    "                chr_contigs[lengths_idx[i]:lengths_idx[i+1]] = seq_subset_mapped\n",
    "            chr_contigs.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05917d",
   "metadata": {},
   "source": [
    "The loop below uses the iterator defined above, opens the targets bw files, extracts the gaps, and saves the result as a memory map, where all the gap-free targets are sequentially stacked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d384cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_path_list = [os.path.join(target_dir, tar) for tar in targets_list]\n",
    "for key in chrom_gaps.keys():\n",
    "    print (key)\n",
    "    memmap_name = key + \"_sequence.dta\"\n",
    "    els_corrected = chrom_gaps[key]\n",
    "    lengths = [e[1] - e[0] for e in els_corrected]\n",
    "    contigs_shape = sum(lengths)\n",
    "    lengths.insert(0, 0)\n",
    "    lengths_idx = np.cumsum(lengths)\n",
    "    chr_contigs =  np.memmap(os.path.join(targets_memmap_data_dir, (key + \"_targets_contigs_sequence.dta\")), mode='w+', dtype='float32', shape=(len(targets_list), contigs_shape))\n",
    "    for i in range(len(els_corrected)):\n",
    "        for j in range(len(targets_path_list)):\n",
    "            target = pyBigWig.open(targets_path_list[j], 'r')\n",
    "            chr_contigs[j, lengths_idx[i]:lengths_idx[i+1]] = target.values(key, els_corrected[i][0], els_corrected[i][1])\n",
    "    chr_contigs.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenji_pytorch",
   "language": "python",
   "name": "basenji_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
